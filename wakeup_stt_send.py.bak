import pvporcupine
import pyaudio
import struct
import sounddevice as sd
import queue
import json
import time
import threading
from vosk import Model, KaldiRecognizer
import socket

AUDIO_RATE = 16000
q = queue.Queue()
recognize_now = False 
model = Model("model")

def send_text_to_pi1(text):
    HOST = '192.168.1.111'  
    PORT = 60002
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.connect((HOST, PORT))
            s.sendall(text.encode('utf-8'))
            print(">> Pi1에게 텍스트 전송 완료:", text)
    except Exception as e:
        print(">> 전송 실패:", e)

def wake_word_listener():
    global recognize_now
    porcupine = pvporcupine.create(
        access_key="qvg3+n8HIzQe1zCVVhps8yXTNYjlGO52eQ7RTk9T5/E90OS7+KespA==",
        keyword_paths=["porcupine/bumblebee_raspberry-pi.ppn"]
    )

    pa = pyaudio.PyAudio()
    stream = pa.open(
        rate=porcupine.sample_rate,
        channels=1,
        format=pyaudio.paInt16,
        input=True,
        frames_per_buffer=porcupine.frame_length
    )

    print(">> Wake word 대기 중... ('Hi Telly')")
    while True:
        pcm = stream.read(porcupine.frame_length, exception_on_overflow=False)
        pcm = struct.unpack_from("h" * porcupine.frame_length, pcm)

        result = porcupine.process(pcm)
        if result >= 0:
            print(">> Wake word 감지됨!")
            recognize_now = True
            time.sleep(0.5) 

def vosk_listener():
    global recognize_now
    recognizer = KaldiRecognizer(model, AUDIO_RATE)

    with sd.RawInputStream(samplerate=AUDIO_RATE, blocksize=8000, dtype='int16',
                           channels=1, callback=lambda indata, f, t, s: q.put(bytes(indata))):
        print(">> 마이크 시작됨.")
        while True:
            data = q.get()

            if not recognize_now:
                continue

            if recognizer.AcceptWaveform(data):
                res = json.loads(recognizer.Result())
                text = res.get("text", "")
                print("[인식 결과]:", text)

                if text.strip():
                    send_text_to_pi1(text) 
                recognize_now = False
                recognizer = KaldiRecognizer(model, AUDIO_RATE) 
                print(">> 다시 wake word 대기 중...")



if __name__ == "__main__":
    thread1 = threading.Thread(target=wake_word_listener)
    thread2 = threading.Thread(target=vosk_listener)

    thread1.start()
    thread2.start()

    thread1.join()
    thread2.join()
